{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/siddharth/VR_ImageProcessing/Bikes_Horses\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    image_paths_horses = glob.glob(\"./Assignment2_BikeHorses/Assignment2_BikeHorses/Horses/*.jpg\")\n",
    "    image_paths_bike = glob.glob(\"./Assignment2_BikeHorses/Assignment2_BikeHorses/Bikes/*.jpg\")\n",
    "    labels = []\n",
    "    images = []\n",
    "    for i in image_paths_horses:\n",
    "        img = cv2.imread(i,0)\n",
    "        images.append(img)\n",
    "        labels.append(0)\n",
    "    for i in image_paths_bike:\n",
    "        img = cv2.imread(i,0)\n",
    "        images.append(img)\n",
    "        labels.append(1)\n",
    "    \n",
    "    return np.asarray(images), np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(folder_path, image_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label, class_name in enumerate(['Bikes', 'Horses']):\n",
    "        class_folder = os.path.join(folder_path, class_name)\n",
    "        for file_name in os.listdir(class_folder):\n",
    "            img = cv2.imread(os.path.join(class_folder, file_name), cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, image_size)  # Resize image to a common size\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDescriptorsArray(images, extractor):\n",
    "    descriptors = []\n",
    "\n",
    "    for i in range(0,len(images)): \n",
    "        keypoints,descriptor= extractor.detectAndCompute(images[i], None)\n",
    "        descriptors.extend(descriptor)\n",
    "    \n",
    "    return np.vstack(descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image2vec(images,kmeans,extractor,n_clusters):\n",
    "    vec = []\n",
    "    for image in images:\n",
    "\n",
    "        keypoints,descriptor = extractor.detectAndCompute(image, None)\n",
    "        img_vec = [0]*n_clusters\n",
    "        for d in descriptor:\n",
    "            s = d.reshape(1,-1)\n",
    "            c = kmeans.predict(s)\n",
    "            img_vec[c[0]] +=1 \n",
    "        vec.append(img_vec)\n",
    "\n",
    "    return np.array(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_codebook(descriptors, num_clusters):\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42, verbose=0)\n",
    "    kmeans.fit(descriptors)\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMisclassificationsSIFT(labels, df, model, images, type):\n",
    "    dir = os.getcwd()\n",
    "\n",
    "    predictions = model.predict(df)\n",
    "    misclassified = []\n",
    "    for i in range(len(predictions)):\n",
    "        if (labels[i] != predictions[i]):\n",
    "            misclassified.append(i)\n",
    "\n",
    "    for i in misclassified:\n",
    "        filename = os.path.join(dir, f'Misclassify_SIFT_{type}_{i}.jpg')\n",
    "        cv2.imwrite(filename, images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMisclassificationsORB(labels, df, model, images, type):\n",
    "    dir = os.getcwd()\n",
    "\n",
    "    predictions = model.predict(df)\n",
    "    misclassified = []\n",
    "    for i in range(len(predictions)):\n",
    "        if (labels[i] != predictions[i]):\n",
    "            misclassified.append(i)\n",
    "\n",
    "    for i in misclassified:\n",
    "        filename = os.path.join(dir, f'Misclassify_ORB_{type}_{i}.jpg')\n",
    "        cv2.imwrite(filename, images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11844/2513039645.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.asarray(images), np.asarray(labels)\n"
     ]
    }
   ],
   "source": [
    "images, labels = read_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIFT Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ... 18.  7.  2.]\n",
      " [ 6.  9. 48. ...  1.  0.  4.]\n",
      " [ 0.  0.  1. ...  0.  0.  1.]\n",
      " ...\n",
      " [64.  4.  0. ...  0.  1.  8.]\n",
      " [22.  6.  1. ...  0.  0.  6.]\n",
      " [54. 12.  3. ...  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "extractor = cv2.SIFT_create()\n",
    "descriptors = getDescriptorsArray(images, extractor)\n",
    "print(descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddharth/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_clusters = 200\n",
    "\n",
    "kmeans = generate_codebook(descriptors, num_clusters)\n",
    "vec = image2vec(images,kmeans,extractor,num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(vec)\n",
    "labels = pd.DataFrame({\"labels\":labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.asarray(labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, labels, test_size=0.2, random_state=42, stratify=labels, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9722222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddharth/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train,y_train)\n",
    "print(svc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "getMisclassificationsSIFT(labels, df, svc, images, \"SVC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9722222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddharth/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "svc_linear = SVC(kernel='linear')\n",
    "svc_linear.fit(X_train,y_train)\n",
    "print(svc_linear.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "getMisclassificationsSIFT(labels, df, svc_linear, images, \"SVC_linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddharth/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "getMisclassificationsSIFT(labels, df, lr, images, \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9722222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddharth/anaconda3/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "getMisclassificationsSIFT(labels, df, clf, images, \"KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORB Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11844/2513039645.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.asarray(images), np.asarray(labels)\n"
     ]
    }
   ],
   "source": [
    "images, labels = read_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[182 239  64 ... 255 120 136]\n",
      " [ 43  31  98 ...  46 121 215]\n",
      " [147 214 122 ... 140 137  29]\n",
      " ...\n",
      " [ 24 151 125 ... 128 133 249]\n",
      " [181  86 236 ... 248 216 113]\n",
      " [129  50 236 ... 192  85 125]]\n"
     ]
    }
   ],
   "source": [
    "extractor = cv2.ORB_create()\n",
    "descriptors = getDescriptorsArray(images, extractor)\n",
    "print(descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddharth/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_clusters = 200\n",
    "\n",
    "kmeans = generate_codebook(descriptors, num_clusters)\n",
    "vec = image2vec(images,kmeans,extractor,num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(vec)\n",
    "labels = pd.DataFrame({\"labels\":labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, labels, test_size=0.2, random_state=42, stratify=labels, shuffle=True)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddharth/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train,y_train)\n",
    "print(svc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "getMisclassificationsORB(labels, df, svc, images, \"SVC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddharth/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "svc_linear = SVC(kernel='linear')\n",
    "svc_linear.fit(X_train,y_train)\n",
    "print(svc_linear.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "getMisclassificationsORB(labels, df, svc_linear, images, \"SVC_linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddharth/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/siddharth/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "getMisclassificationsORB(labels, df, lr, images, \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8055555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddharth/anaconda3/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "getMisclassificationsORB(labels, df, clf, images, \"KNN\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "722f87b190e09c406b51296d764657807ebdfc3da2dcef48223aae467148a787"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
