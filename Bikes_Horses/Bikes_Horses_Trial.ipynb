{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    image_paths_horses = glob.glob(\"./Assignment2_BikeHorses/Assignment2_BikeHorses/Horses/*.jpg\")\n",
    "    image_paths_bike = glob.glob(\"./Assignment2_BikeHorses/Assignment2_BikeHorses/Bikes/*.jpg\")\n",
    "    labels = []\n",
    "    images = []\n",
    "    for i in image_paths_horses:\n",
    "        img = cv2.imread(i,0)\n",
    "        images.append(img)\n",
    "        labels.append(0)\n",
    "    for i in image_paths_bike:\n",
    "        img = cv2.imread(i,0)\n",
    "        images.append(img)\n",
    "        labels.append(1)\n",
    "    \n",
    "    return np.asarray(images), np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(folder_path, image_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label, class_name in enumerate(['Bikes', 'Horses']):\n",
    "        class_folder = os.path.join(folder_path, class_name)\n",
    "        for file_name in os.listdir(class_folder):\n",
    "            img = cv2.imread(os.path.join(class_folder, file_name), cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, image_size)  # Resize image to a common size\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDescriptorsArray(images, extractor):\n",
    "    descriptors = []\n",
    "\n",
    "    for i in range(0,len(images)): \n",
    "        keypoints,descriptor= extractor.detectAndCompute(images[i], None)\n",
    "        descriptors.extend(descriptor)\n",
    "    \n",
    "    return np.vstack(descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image2vec(images,kmeans,extractor,n_clusters):\n",
    "    vec = []\n",
    "    for image in images:\n",
    "\n",
    "        keypoints,descriptor = extractor.detectAndCompute(image, None)\n",
    "        img_vec = [0]*n_clusters\n",
    "        for d in descriptor:\n",
    "            s = d.reshape(1,-1)\n",
    "            c = kmeans.predict(s)\n",
    "            img_vec[c[0]] +=1 \n",
    "        vec.append(img_vec)\n",
    "\n",
    "    return np.array(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_codebook(descriptors, num_clusters):\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42, verbose=0)\n",
    "    kmeans.fit(descriptors)\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMisclassificationsSIFT(labels, df, model, images, type):\n",
    "    dir = os.getcwd()\n",
    "\n",
    "    predictions = model.predict(df)\n",
    "    misclassified = []\n",
    "    for i in range(len(predictions)):\n",
    "        if (labels[i] != predictions[i]):\n",
    "            misclassified.append(i)\n",
    "\n",
    "    for i in misclassified:\n",
    "        filename = os.path.join(dir, f'Misclassify_SIFT_{type}_{i}.jpg')\n",
    "        cv2.imwrite(filename, images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMisclassificationsORB(labels, df, model, images, type):\n",
    "    dir = os.getcwd()\n",
    "\n",
    "    predictions = model.predict(df)\n",
    "    misclassified = []\n",
    "    for i in range(len(predictions)):\n",
    "        if (labels[i] != predictions[i]):\n",
    "            misclassified.append(i)\n",
    "\n",
    "    for i in misclassified:\n",
    "        filename = os.path.join(dir, f'Misclassify_ORB_{type}_{i}.jpg')\n",
    "        cv2.imwrite(filename, images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = read_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIFT Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = cv2.SIFT_create()\n",
    "descriptors = getDescriptorsArray(images, extractor)\n",
    "print(descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 200\n",
    "\n",
    "kmeans = generate_codebook(descriptors, num_clusters)\n",
    "vec = image2vec(images,kmeans,extractor,num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(vec)\n",
    "labels = pd.DataFrame({\"labels\":labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.asarray(labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, labels, test_size=0.2, random_state=42, stratify=labels, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train,y_train)\n",
    "print(svc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getMisclassificationsSIFT(labels, df, svc, images, \"SVC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_linear = SVC(kernel='linear')\n",
    "svc_linear.fit(X_train,y_train)\n",
    "print(svc_linear.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getMisclassificationsSIFT(labels, df, svc_linear, images, \"SVC_linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getMisclassificationsSIFT(labels, df, lr, images, \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getMisclassificationsSIFT(labels, df, clf, images, \"KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORB Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = read_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = cv2.ORB_create()\n",
    "descriptors = getDescriptorsArray(images, extractor)\n",
    "print(descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 200\n",
    "\n",
    "kmeans = generate_codebook(descriptors, num_clusters)\n",
    "vec = image2vec(images,kmeans,extractor,num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(vec)\n",
    "labels = pd.DataFrame({\"labels\":labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, labels, test_size=0.2, random_state=42, stratify=labels, shuffle=True)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train,y_train)\n",
    "print(svc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getMisclassificationsORB(labels, df, svc, images, \"SVC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_linear = SVC(kernel='linear')\n",
    "svc_linear.fit(X_train,y_train)\n",
    "print(svc_linear.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getMisclassificationsORB(labels, df, svc_linear, images, \"SVC_linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getMisclassificationsORB(labels, df, lr, images, \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getMisclassificationsORB(labels, df, clf, images, \"KNN\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "722f87b190e09c406b51296d764657807ebdfc3da2dcef48223aae467148a787"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
