{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "import pickle \n",
    "import glob \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "image_paths_train = glob.glob('./Assignment2_BikeHorses/Assignment2_BikeHorses/cifar-10-python/cifar-10-batches-py/data_batch_*')\n",
    "image_paths_test = glob.glob('./Assignment2_BikeHorses/Assignment2_BikeHorses/cifar-10-python/cifar-10-batches-py/test_batch')\n",
    "extractor = cv2.SIFT_create()\n",
    "\n",
    "def features(image, extractor):\n",
    "    keypoints, descriptors = extractor.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = []\n",
    "\n",
    "for i in image_paths_train:\n",
    "    image_dict.append(unpickle(i))\n",
    "\n",
    "image_dict.append(unpickle(image_paths_test[0]))\n",
    "\n",
    "image_dict[0].keys()\n",
    "dat = image_dict[0][b'data']\n",
    "\n",
    "container = np.vstack([d[b'data'] for d in image_dict])\n",
    "labels = np.vstack([d[b'labels'] for d in image_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrayToImage(img):\n",
    "    red = np.reshape(img[:img.shape[0]//3],(32,32,))\n",
    "    green =  np.reshape(img[img.shape[0]//3:2*img.shape[0]//3],(32,32,))\n",
    "    blue = np.reshape(img[2*img.shape[0]//3:img.shape[0]],(32,32,))\n",
    "    img = np.stack([red, green, blue], axis=2)\n",
    "    return img \n",
    "\n",
    "images = []\n",
    "\n",
    "for i in container:\n",
    "    images.append(arrayToImage(i))\n",
    "\n",
    "indicies_used = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(images):\n",
    "\n",
    "    descriptors = pd.DataFrame([])\n",
    "    for i in range(0,len(images)):\n",
    "        _,descriptor = features(images[i],extractor)\n",
    "        if descriptor is not None:\n",
    "            descriptors=pd.concat((descriptors,pd.DataFrame(descriptor)),axis=0)\n",
    "            indicies_used.append(i)\n",
    "    return descriptors  \n",
    "\n",
    "img2v = preprocess(images)\n",
    "ind = pd.DataFrame(indicies_used)\n",
    "print(ind.shape)\n",
    "print(img2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=12, random_state=42,verbose=0)\n",
    "kmeans.fit(img2v)\n",
    "n_clusters = 500 \n",
    "\n",
    "im2v = []\n",
    "\n",
    "for i in range(len(images)):\n",
    "    _,descriptor = features(images[i],extractor)\n",
    "    img_vec = [0]*n_clusters\n",
    "    if descriptor is not None:\n",
    "        for d in descriptor:\n",
    "            s = d.reshape(1,-1)\n",
    "            c = kmeans.predict(s)\n",
    "            img_vec[c[0]] +=1 \n",
    "        im2v.append(img_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([*im2v])\n",
    "\n",
    "lab = []\n",
    "\n",
    "for l in labels:\n",
    "    for k in l:\n",
    "        lab.append(k)\n",
    "\n",
    "lab_final = [lab[i] for i in indicies_used]\n",
    "labels = pd.DataFrame({\"labels\":lab_final})\n",
    "df = pd.concat([df,labels],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "df_train=df.drop(['labels'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train, df['labels'], test_size=0.20, random_state=42,stratify=df['labels'],shuffle=True)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# import optuna\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# def objective_svm(trial):\n",
    "#     C = trial.suggest_loguniform('C', 1e-10, 1e10)\n",
    "#     gamma = trial.suggest_loguniform('gamma', 1e-10, 1e10)\n",
    "#     clf = SVC(C=C, gamma=gamma)\n",
    "#     return cross_val_score(clf, X_train, y_train, n_jobs=-1, cv=3).mean()\n",
    "\n",
    "# def objective_lr(trial):\n",
    "#     C = trial.suggest_loguniform('C', 1e-10, 1e10)\n",
    "#     clf = LogisticRegression(C=C, random_state=42)\n",
    "#     return cross_val_score(clf, X_train, y_train, n_jobs=-1, cv=3).mean()\n",
    "\n",
    "# def objective_knn(trial):\n",
    "#     n_neighbors = trial.suggest_int('n_neighbors', 1, 20)\n",
    "#     knn_clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "#     return cross_val_score(knn_clf, X_train, y_train, n_jobs=-1, cv=3).mean()\n",
    "\n",
    "# study_svm = optuna.create_study(direction='maximize')\n",
    "# study_svm.optimize(objective_svm, n_trials=100)\n",
    "\n",
    "# study_lr = optuna.create_study(direction='maximize')\n",
    "# study_lr.optimize(objective_lr, n_trials=100)\n",
    "\n",
    "# study_knn = optuna.create_study(direction='maximize')\n",
    "# study_knn.optimize(objective_knn, n_trials=100)\n",
    "\n",
    "# # Get best parameters\n",
    "# best_params_svm = study_svm.best_params\n",
    "# best_params_lr = study_lr.best_params\n",
    "# best_params_knn = study_knn.best_params\n",
    "\n",
    "# Train classifiers with best parameters\n",
    "best_svm = SVC()\n",
    "best_svm.fit(X_train, y_train)\n",
    "y_pred = best_svm.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_pred, y_test)\n",
    "# svm_accuracy = silhouette_scoree(X_test, y_test)\n",
    "\n",
    "print(\"SVM Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = LogisticRegression(random_state=42)\n",
    "best_lr.fit(X_train, y_train)\n",
    "y_pred = best_lr.predict(X_test)\n",
    "lr_accuracy = best_lr.score(X_test, y_test)\n",
    "\n",
    "best_knn = KNeighborsClassifier()\n",
    "best_knn.fit(X_train, y_train)\n",
    "y_pred = best_knn.predict(X_test)\n",
    "knn_accuracy = best_knn.score(X_test, y_test)\n",
    "print(\"LR Accuracy:\", lr_accuracy)\n",
    "print(\"KNN Accuracy:\", knn_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
