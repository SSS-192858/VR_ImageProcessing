{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.12475953831356204\n",
      "Test Accuracy: 0.10485164394546913\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return images\n",
    "\n",
    "train_images = preprocess(train_images)\n",
    "test_images = preprocess(test_images)\n",
    "\n",
    "# Feature extraction using SIFT\n",
    "def extract_sift_features(images):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints_list = []\n",
    "    descriptors_list = []\n",
    "    for image in images:\n",
    "        image = (image * 255).astype(np.uint8)  # Convert image to uint8\n",
    "        keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "        if descriptors is not None and len(keypoints) > 0:  # Ensure valid descriptors\n",
    "            descriptors_list.append(descriptors)\n",
    "            keypoints_list.append(keypoints)\n",
    "    return keypoints_list, descriptors_list\n",
    "\n",
    "train_keypoints, train_descriptors = extract_sift_features(train_images)\n",
    "test_keypoints, test_descriptors = extract_sift_features(test_images)\n",
    "\n",
    "# Flatten descriptors\n",
    "train_descriptors_flat = np.vstack(train_descriptors)\n",
    "test_descriptors_flat = np.vstack(test_descriptors)\n",
    "\n",
    "# K-means clustering\n",
    "kmeans = KMeans(n_clusters=100)\n",
    "kmeans.fit(train_descriptors_flat)\n",
    "\n",
    "# Generate Bag-of-Visual Words representation\n",
    "def bow_representation(keypoints, descriptors, kmeans):\n",
    "    bow_representation = np.zeros((len(keypoints), kmeans.n_clusters), dtype=np.float32)\n",
    "    for i in range(len(keypoints)):\n",
    "        if descriptors[i] is not None:\n",
    "            words = kmeans.predict(descriptors[i])\n",
    "            for word in words:\n",
    "                bow_representation[i, word] += 1\n",
    "    return bow_representation\n",
    "\n",
    "train_bow = bow_representation(train_keypoints, train_descriptors, kmeans)\n",
    "test_bow = bow_representation(test_keypoints, test_descriptors, kmeans)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "train_bow_scaled = scaler.fit_transform(train_bow)\n",
    "test_bow_scaled = scaler.transform(test_bow)\n",
    "\n",
    "# SVM classifier\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(train_bow_scaled, train_labels[:len(train_bow)].ravel())\n",
    "\n",
    "# Predictions\n",
    "train_predictions = svm.predict(train_bow_scaled)\n",
    "test_predictions = svm.predict(test_bow_scaled)\n",
    "\n",
    "# Accuracy\n",
    "train_accuracy = accuracy_score(train_labels[:len(train_bow)], train_predictions)\n",
    "test_accuracy = accuracy_score(test_labels[:len(test_bow)], test_predictions)\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
