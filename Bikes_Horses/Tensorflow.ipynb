{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(images):\n",
    "    images = images.astype('float32') / 255.0\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sift_features(images):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints_list = []\n",
    "    descriptors_list = []\n",
    "    for image in images:\n",
    "        image = (image * 255).astype(np.uint8)  # Convert image to uint8\n",
    "        keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "        if descriptors is not None and len(keypoints) > 0:  # Ensure valid descriptors\n",
    "            descriptors_list.append(descriptors)\n",
    "            keypoints_list.append(keypoints)\n",
    "    return keypoints_list, descriptors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_representation(keypoints, descriptors, kmeans):\n",
    "    bow_representation = np.zeros((len(keypoints), kmeans.n_clusters), dtype=np.float32)\n",
    "    for i in range(len(keypoints)):\n",
    "        if descriptors[i] is not None:\n",
    "            words = kmeans.predict(descriptors[i])\n",
    "            for word in words:\n",
    "                bow_representation[i, word] += 1\n",
    "    return bow_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "train_images = preprocess(train_images)\n",
    "test_images = preprocess(test_images)\n",
    "\n",
    "# Feature extraction using SIFT\n",
    "\n",
    "\n",
    "train_keypoints, train_descriptors = extract_sift_features(train_images)\n",
    "test_keypoints, test_descriptors = extract_sift_features(test_images)\n",
    "\n",
    "# Flatten descriptors\n",
    "train_descriptors_flat = np.vstack(train_descriptors)\n",
    "test_descriptors_flat = np.vstack(test_descriptors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=12, random_state=42)\n",
    "kmeans.fit(train_descriptors_flat)\n",
    "\n",
    "# Generate Bag-of-Visual Words representation\n",
    "\n",
    "\n",
    "train_bow = bow_representation(train_keypoints, train_descriptors, kmeans)\n",
    "test_bow = bow_representation(test_keypoints, test_descriptors, kmeans)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "train_bow_scaled = scaler.fit_transform(train_bow)\n",
    "test_bow_scaled = scaler.transform(test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "\n",
    "\n",
    "# def objective(trial):\n",
    "#     C = trial.suggest_loguniform('C', 1e-10, 1e10)\n",
    "#     # kernel = trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly', 'sigmoid'])\n",
    "#     svm = SVC(C=C, kernel='linear')\n",
    "    \n",
    "#     # Fit the classifier to the training data\n",
    "#     svm.fit(train_bow_scaled, train_labels[:len(train_bow)].ravel())\n",
    "\n",
    "#     # Make predictions on the training and test data\n",
    "#     train_predictions = svm.predict(train_bow_scaled)\n",
    "#     test_predictions = svm.predict(test_bow_scaled)\n",
    "\n",
    "#     # Calculate accuracy\n",
    "#     train_accuracy = accuracy_score(train_labels[:len(train_bow)], train_predictions)\n",
    "#     test_accuracy = accuracy_score(test_labels[:len(test_bow)], test_predictions)\n",
    "\n",
    "#     # Return the test accuracy as the objective value to maximize\n",
    "#     return test_accuracy\n",
    "\n",
    "# # Create a study object and optimize the objective function\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "# best_params = study.best_params\n",
    "best_svm = SVC()\n",
    "\n",
    "# Fit the classifier with the best hyperparameters\n",
    "best_svm.fit(train_bow_scaled, train_labels[:len(train_bow)].ravel())\n",
    "\n",
    "# Make predictions on the test data using the best classifier\n",
    "test_predictions = best_svm.predict(test_bow_scaled)\n",
    "\n",
    "# silhouette = silhouette_score(test_bow_scaled, test_labels)\n",
    "# print(\"Silhouette Score:\", silhouette)\n",
    "# Calculate accuracy\n",
    "test_accuracy = accuracy_score(test_labels[:len(test_bow)], test_predictions)\n",
    "\n",
    "# print(\"Best hyperparameters:\", best_params)\n",
    "# print(\"Test Accuracy with best model:\", test_accuracy)/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "#     C = trial.suggest_loguniform('C', 1e-10, 1e10)\n",
    "#     max_iter = trial.suggest_int('max_iter', 100, 1000)\n",
    "    \n",
    "#     # Initialize the classifier with the suggested hyperparameters\n",
    "#     clf = LogisticRegression(C=C, max_iter=max_iter, random_state=42)\n",
    "    \n",
    "#     # Fit the classifier to the training data\n",
    "#     clf.fit(train_bow_scaled, train_labels[:len(train_bow)].ravel())\n",
    "\n",
    "#     # Make predictions on the training and test data\n",
    "#     train_predictions = clf.predict(train_bow_scaled)\n",
    "#     test_predictions = clf.predict(test_bow_scaled)\n",
    "\n",
    "#     # Calculate accuracy\n",
    "#     train_accuracy = accuracy_score(train_labels[:len(train_bow)], train_predictions)\n",
    "#     test_accuracy = accuracy_score(test_labels[:len(test_bow)], test_predictions)\n",
    "\n",
    "#     # Return the test accuracy as the objective value to maximize\n",
    "#     return test_accuracy\n",
    "\n",
    "# # Create a study object and optimize the objective function\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=100)\n",
    "\n",
    "# # Get the best hyperparameters\n",
    "# best_params = study.best_params\n",
    "best_lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# Fit the classifier with the best hyperparameters\n",
    "best_lr.fit(train_bow_scaled, train_labels[:len(train_bow)].ravel())\n",
    "\n",
    "# Make predictions on the test data using the best classifier\n",
    "test_predictions = best_lr.predict(test_bow_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "test_accuracy = accuracy_score(test_labels[:len(test_bow)], test_predictions)\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Test Accuracy with best model:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "# def objective(trial):\n",
    "#     n_neighbors = trial.suggest_int('n_neighbors', 1, 100)\n",
    "#     knn_clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    \n",
    "#     # Fit the classifier to the training data\n",
    "#     knn_clf.fit(train_bow_scaled, train_labels[:len(train_bow)].ravel())\n",
    "\n",
    "#     # Make predictions on the training and test data\n",
    "#     train_predictions = knn_clf.predict(train_bow_scaled)\n",
    "#     test_predictions = knn_clf.predict(test_bow_scaled)\n",
    "\n",
    "#     # Calculate accuracy\n",
    "#     train_accuracy = accuracy_score(train_labels[:len(train_bow)], train_predictions)\n",
    "#     test_accuracy = accuracy_score(test_labels[:len(test_bow)], test_predictions)\n",
    "\n",
    "#     # Return the test accuracy as the objective value to maximize\n",
    "#     return test_accuracy\n",
    "\n",
    "# # Create a study object and optimize the objective function\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=10)\n",
    "\n",
    "# # Get the best hyperparameters\n",
    "# best_params = study.best_params\n",
    "best_knn = KNeighborsClassifier()\n",
    "\n",
    "# Fit the classifier with the best hyperparameters\n",
    "best_knn.fit(train_bow_scaled, train_labels[:len(train_bow)].ravel())\n",
    "\n",
    "# Make predictions on the test data using the best classifier\n",
    "test_predictions = best_knn.predict(test_bow_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "test_accuracy = accuracy_score(test_labels[:len(test_bow)], test_predictions)\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Test Accuracy with best model:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
