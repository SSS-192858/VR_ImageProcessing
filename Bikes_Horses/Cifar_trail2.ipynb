{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "import glob \n",
    "import pandas as pd \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrayToImage(img):\n",
    "    red = np.reshape(img[:img.shape[0]//3],(32,32,))\n",
    "    green =  np.reshape(img[img.shape[0]//3:2*img.shape[0]//3],(32,32,))\n",
    "    blue = np.reshape(img[2*img.shape[0]//3:img.shape[0]],(32,32,))\n",
    "    img = np.stack([red, green, blue], axis=2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints = []\n",
    "    descriptors = []\n",
    "    for image in images:\n",
    "        kp, desc = sift.detectAndCompute(image, None)\n",
    "        keypoints.append(kp)\n",
    "        descriptors.append(desc)\n",
    "    return keypoints, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_codebook(descriptors, num_clusters):\n",
    "    all_descriptors = np.concatenate(descriptors, axis=0)\n",
    "    kmeans = KMeans(n_clusters=num_clusters)\n",
    "    kmeans.fit(all_descriptors)\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_features(descriptors, codebook):\n",
    "    quantized_features = []\n",
    "    for desc in descriptors:\n",
    "        labels = codebook.predict(desc)\n",
    "        hist, _ = np.histogram(labels, bins=range(codebook.n_clusters + 1), density=True)\n",
    "        quantized_features.append(hist)\n",
    "    return np.array(quantized_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(features, labels, option, k=None):\n",
    "    if option == \"SVC\":\n",
    "        clf = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "    elif option == \"KNN\":\n",
    "        clf = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=k))\n",
    "    elif option == \"LogR\":\n",
    "        clf = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "    else:\n",
    "        print(\"Invalid option. Please choose from 'SVC', 'KNN', or 'LogR'.\")\n",
    "    \n",
    "    clf.fit(features, labels)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(clf, test_features, test_labels):\n",
    "    predictions = clf.predict(test_features)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths_train = glob.glob('./Assignment2_BikeHorses/Assignment2_BikeHorses/cifar-10-python/cifar-10-batches-py/data_batch_*')\n",
    "image_paths_test = glob.glob('./Assignment2_BikeHorses/Assignment2_BikeHorses/cifar-10-python/cifar-10-batches-py/test_batch')\n",
    "\n",
    "image_dict_train = []\n",
    "for i in image_paths_train:\n",
    "    image_dict_train.append(unpickle(i))\n",
    "image_dict_train.append(unpickle(image_paths_test[0]))\n",
    "\n",
    "image_dict_test =[]\n",
    "for i in image_paths_test:\n",
    "    image_dict_test.append(unpickle(i))\n",
    "image_dict_test.append(unpickle(image_paths_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_train = np.vstack([d[b'data'] for d in image_dict_train])\n",
    "labels_train = np.vstack([d[b'labels'] for d in image_dict_train])\n",
    "\n",
    "container_test = np.vstack([d[b'data'] for d in image_dict_test])\n",
    "labels_test = np.vstack([d[b'labels'] for d in image_dict_test])\n",
    "\n",
    "\n",
    "images_train = []\n",
    "for i in container_train:\n",
    "    images_train.append(arrayToImage(i))\n",
    "\n",
    "images_test = []\n",
    "for i in container_test:\n",
    "    images_test.append(arrayToImage(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "# Feature extraction\n",
    "train_keypoints, train_descriptors = extract_features(images_train)\n",
    "test_keypoints, test_descriptors = extract_features(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 100  # Adjust as needed\n",
    "codebook = generate_codebook(train_descriptors, num_clusters)\n",
    "\n",
    "# Feature quantization\n",
    "train_features = quantize_features(train_descriptors, codebook)\n",
    "test_features = quantize_features(test_descriptors, codebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = train_classifier(train_features, labels_train,\"LogR\",5)\n",
    "\n",
    "# Evaluate classifier\n",
    "accuracy = evaluate_classifier(clf, test_features, test_labels)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
